{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# DNN: deep neural network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tensorflow 2.0에 내장된 Keras 사용\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용 함수\n",
    "from tensorflow.keras.layers import Dense       # 전결합층\n",
    "from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "\n",
    "# tensorflow 1.x, Keras가 독립적으로 설치된 경우\n",
    "# from keras.models import Sequential  # class\n",
    "# from keras.models import load_model  # model 사용 함수\n",
    "# from keras.layers import Dense       # class\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[ 1 10]\n",
      " [ 2 10]\n",
      " [ 3 10]\n",
      " [ 4 10]\n",
      " [ 5 10]]\n"
     ]
    }
   ],
   "source": [
    "# 입력 값이 2개이므로 2차원 배열로 데이터 구성\n",
    "\n",
    "# 훈련 데이터: 수\n",
    "x_train = []\n",
    "for i in range(1, 101, 1): # 1 ~ 100\n",
    "    x_train.append([i, 10])\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train[0:5]) # 5행만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ 1 10]  -> 68\n",
    "# [ 2 10]  -> 143\n",
    "# [ 3 10]  -> 218\n",
    "# [ 4 10]  -> 293\n",
    "# [ 5 10]  -> 368\n",
    "# [ 6 10]  -> ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "[[ 68.]\n",
      " [143.]\n",
      " [218.]\n",
      " [293.]\n",
      " [368.]]\n"
     ]
    }
   ],
   "source": [
    "# 타겟(실제값)\n",
    "y_train = []\n",
    "for i in range(len(x_train)):\n",
    "    val = (x_train[i][0] * x_train[i][1]) / 2 * 5 * 3 - 7\n",
    "    y_train.append([val]) # 2차원의 형태로 추가\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/300\n",
      "80/80 [==============================] - 1s 10ms/sample - loss: 12576544.3087 - val_loss: 47589162.0000\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12552586.9200 - val_loss: 47501922.6000\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12527886.2135 - val_loss: 47419281.8000\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12503366.6568 - val_loss: 47333228.4000\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12479008.4336 - val_loss: 47246433.4000\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12454586.2559 - val_loss: 47164251.8000\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12430682.8629 - val_loss: 47078821.0000\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12406446.4288 - val_loss: 46994327.0000\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12382146.1896 - val_loss: 46911456.2000\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12358069.6049 - val_loss: 46826047.2000\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12333928.8471 - val_loss: 46739518.0000\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12309720.4201 - val_loss: 46656401.2000\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12285721.0930 - val_loss: 46572860.8000\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12261613.0327 - val_loss: 46493542.2000\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12237901.0953 - val_loss: 46404650.4000\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12213715.5183 - val_loss: 46322721.2000\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12189889.8175 - val_loss: 46238212.2000\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12165873.7508 - val_loss: 46155202.6000\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12142050.8542 - val_loss: 46071100.2000\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12118140.0539 - val_loss: 45990701.4000\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12094426.4344 - val_loss: 45905049.4000\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12070475.2039 - val_loss: 45823303.4000\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12046695.0055 - val_loss: 45740195.4000\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 12022995.7972 - val_loss: 45655696.2000\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11999367.7888 - val_loss: 45572256.6000\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11975701.9301 - val_loss: 45490538.8000\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11952159.7970 - val_loss: 45408742.4000\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11928403.3631 - val_loss: 45328499.4000\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11904931.4204 - val_loss: 45243967.2000\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11881496.0864 - val_loss: 45159813.4000\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11857854.6250 - val_loss: 45078077.8000\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11834448.7982 - val_loss: 44995292.8000\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11810719.6246 - val_loss: 44918504.2000\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11787482.4572 - val_loss: 44832987.6000\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11763995.2187 - val_loss: 44749991.8000\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11740494.6353 - val_loss: 44670752.0000\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11717234.0216 - val_loss: 44587371.2000\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11693904.9236 - val_loss: 44505690.8000\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11670579.9575 - val_loss: 44423405.4000\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11647142.2353 - val_loss: 44346231.4000\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11624275.6722 - val_loss: 44258162.0000\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11600681.3920 - val_loss: 44180447.2000\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11577539.8387 - val_loss: 44098888.2000\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11554268.4883 - val_loss: 44019580.2000\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11531227.3456 - val_loss: 43937952.8000\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11508034.3120 - val_loss: 43857877.2000\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11484973.8604 - val_loss: 43775715.8000\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11461830.5535 - val_loss: 43695661.6000\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11438786.9196 - val_loss: 43614944.2000\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11415759.6092 - val_loss: 43533930.0000\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11392751.6615 - val_loss: 43453882.2000\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11369951.7050 - val_loss: 43370200.8000\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11346911.7227 - val_loss: 43288792.0000\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11323804.6764 - val_loss: 43212746.8000\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11301125.2175 - val_loss: 43131024.8000\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11278185.0217 - val_loss: 43051734.4000\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11255392.1561 - val_loss: 42971012.0000\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11232711.9490 - val_loss: 42889814.0000\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11209719.2705 - val_loss: 42812581.4000\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11187032.3613 - val_loss: 42731713.2000\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11164334.6295 - val_loss: 42651766.6000\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11141591.1080 - val_loss: 42571234.8000\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11118957.8122 - val_loss: 42490338.6000\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11096212.8807 - val_loss: 42411837.0000\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11073577.9431 - val_loss: 42333292.8000\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11050912.2604 - val_loss: 42253818.6000\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11028378.4935 - val_loss: 42173481.4000\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 11005757.7526 - val_loss: 42095112.5000\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10983328.0224 - val_loss: 42015385.8000\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10960682.1843 - val_loss: 41939538.7000\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/sample - loss: 10938312.6715 - val_loss: 41862346.4000\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10916031.6598 - val_loss: 41778756.3000\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10893370.6071 - val_loss: 41701932.9000\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10871038.4849 - val_loss: 41623546.5000\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10848600.1772 - val_loss: 41545569.9000\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10826267.6952 - val_loss: 41465893.8000\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10804012.2496 - val_loss: 41384965.6000\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10781663.7610 - val_loss: 41306426.3000\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10759309.9473 - val_loss: 41230306.0000\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10737035.4453 - val_loss: 41153974.6000\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10714836.3688 - val_loss: 41074507.9000\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10692617.4302 - val_loss: 40995037.6000\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10670457.8369 - val_loss: 40917159.5000\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10648127.5090 - val_loss: 40843881.0000\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10626103.1594 - val_loss: 40764345.7000\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10604028.7213 - val_loss: 40683856.2000\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10581795.0054 - val_loss: 40608502.6000\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10559934.8976 - val_loss: 40528936.5000\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10537799.6054 - val_loss: 40452766.1000\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10515798.9584 - val_loss: 40375426.9000\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10493860.7473 - val_loss: 40297135.0000\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10471965.8651 - val_loss: 40218136.7000\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10449936.1365 - val_loss: 40141730.0000\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10428041.9557 - val_loss: 40064921.8000\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10406175.6753 - val_loss: 39988156.1000\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10384219.6633 - val_loss: 39914041.2000\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10362664.5335 - val_loss: 39833602.4000\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10340675.2183 - val_loss: 39758163.9000\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10318895.8223 - val_loss: 39682844.1000\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10297217.6021 - val_loss: 39605138.2000\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10275406.9882 - val_loss: 39528320.1000\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10253811.2786 - val_loss: 39450901.6000\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10232022.2769 - val_loss: 39376090.4000\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10210350.5203 - val_loss: 39299426.9000\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10188589.5746 - val_loss: 39225836.5000\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10167224.7844 - val_loss: 39144870.6000\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10145441.2589 - val_loss: 39069693.2000\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10123794.7148 - val_loss: 38996561.1000\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10102394.1681 - val_loss: 38918755.0000\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10080808.7340 - val_loss: 38843647.6000\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10059243.1816 - val_loss: 38768913.4000\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10037787.0145 - val_loss: 38693266.2000\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 10016425.4984 - val_loss: 38615479.8000\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9994944.9279 - val_loss: 38540036.0000\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9973561.9467 - val_loss: 38465138.4000\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9952271.4636 - val_loss: 38388261.1000\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9930779.5407 - val_loss: 38314701.3000\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9909547.8668 - val_loss: 38239856.8000\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9888263.3683 - val_loss: 38165314.0000\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9866945.2554 - val_loss: 38090040.1000\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9845882.6857 - val_loss: 38012402.1000\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9824411.6255 - val_loss: 37942457.0000\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9803372.2919 - val_loss: 37866167.3000\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9782228.4962 - val_loss: 37789299.7000\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9761114.3753 - val_loss: 37713523.1000\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9739801.3814 - val_loss: 37642434.2000\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9718866.6283 - val_loss: 37565680.6000\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9697796.0528 - val_loss: 37491059.6000\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9676649.4153 - val_loss: 37417485.4000\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9655665.4918 - val_loss: 37344750.9000\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9634677.6556 - val_loss: 37269102.4000\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9613674.8428 - val_loss: 37194413.4000\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9592745.3829 - val_loss: 37121169.1000\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9571792.7988 - val_loss: 37048500.7000\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9550970.8554 - val_loss: 36974159.2000\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9530068.0871 - val_loss: 36902593.1000\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9509284.4970 - val_loss: 36825999.8000\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9488354.4672 - val_loss: 36752360.3000\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9467547.3561 - val_loss: 36678963.2000\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9446766.1537 - val_loss: 36606223.4000\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/sample - loss: 9426207.7686 - val_loss: 36530647.5000\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9405291.4079 - val_loss: 36459988.9000\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9384761.7939 - val_loss: 36384432.1000\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9363992.5942 - val_loss: 36310506.9000\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9343194.9751 - val_loss: 36240892.8000\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9322793.3603 - val_loss: 36165324.7000\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9302097.0988 - val_loss: 36092744.2000\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9281553.1141 - val_loss: 36018907.6000\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9260980.6930 - val_loss: 35947655.0000\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9240342.2547 - val_loss: 35877019.1000\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9219929.0057 - val_loss: 35803073.5000\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9199414.5283 - val_loss: 35728825.3000\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9178773.7074 - val_loss: 35659637.4000\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9158543.3120 - val_loss: 35586022.9000\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9137992.6143 - val_loss: 35513322.4000\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9117654.6817 - val_loss: 35441328.7000\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9097260.2746 - val_loss: 35367987.0000\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9076937.7607 - val_loss: 35295153.6000\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 9056511.1891 - val_loss: 35225335.3000\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9036318.0140 - val_loss: 35151496.5000\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 9016030.3824 - val_loss: 35079342.3000\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8995682.6998 - val_loss: 35009451.3000\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8975522.8424 - val_loss: 34937523.3000\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8955304.6353 - val_loss: 34867803.4000\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8935139.2349 - val_loss: 34795093.6000\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8914972.3029 - val_loss: 34722199.1000\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8894743.4964 - val_loss: 34651234.8000\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8874704.9460 - val_loss: 34577488.5000\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8854455.6865 - val_loss: 34509711.6000\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8834534.2059 - val_loss: 34437664.2000\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8814616.8341 - val_loss: 34363327.0000\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8794389.7689 - val_loss: 34297503.4000\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8774540.1291 - val_loss: 34225216.5000\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8754529.9930 - val_loss: 34154571.9000\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8734661.7394 - val_loss: 34081045.8000\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8714634.0580 - val_loss: 34013102.9000\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8694952.3805 - val_loss: 33940275.8000\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8674949.0633 - val_loss: 33870791.8000\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8655110.9289 - val_loss: 33801599.5000\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8635512.6517 - val_loss: 33728798.5000\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8615633.2460 - val_loss: 33658275.8000\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8595976.1021 - val_loss: 33588301.2000\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8576258.1746 - val_loss: 33518089.9000\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8556452.2318 - val_loss: 33450079.2000\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8536847.9584 - val_loss: 33379639.3000\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8517173.0447 - val_loss: 33309880.1000\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8497561.8465 - val_loss: 33239622.3000\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8477993.1563 - val_loss: 33167833.8000\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8458246.5596 - val_loss: 33100267.9000\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8438775.6734 - val_loss: 33031083.8000\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8419242.1540 - val_loss: 32962752.8000\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8399764.2456 - val_loss: 32891946.7000\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8380341.4230 - val_loss: 32820402.7000\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8360684.9989 - val_loss: 32754828.2000\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8341362.9414 - val_loss: 32685327.2000\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8321991.7353 - val_loss: 32615133.9000\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8302533.2212 - val_loss: 32544645.8000\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8283141.4781 - val_loss: 32476370.5000\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8263762.8940 - val_loss: 32409452.9000\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8244675.8398 - val_loss: 32337129.6000\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8225196.7201 - val_loss: 32270459.4000\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8206001.6069 - val_loss: 32201998.9000\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8186861.1925 - val_loss: 32132966.3000\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8167613.3367 - val_loss: 32063800.5000\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8148295.6773 - val_loss: 31998122.8000\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8129163.8866 - val_loss: 31930198.5000\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8110130.1976 - val_loss: 31859024.2000\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8090939.0840 - val_loss: 31791024.5000\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8071829.7244 - val_loss: 31723308.8000\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8052775.4512 - val_loss: 31655046.4000\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8033696.0869 - val_loss: 31586820.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 8014687.4296 - val_loss: 31518470.9000\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7995546.4381 - val_loss: 31454332.7000\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7976662.9949 - val_loss: 31386982.3000\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7957870.5945 - val_loss: 31314454.2000\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7938616.3489 - val_loss: 31250232.7000\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7919916.5982 - val_loss: 31181366.0000\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7900923.7924 - val_loss: 31115887.3000\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7882295.4429 - val_loss: 31044307.9000\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7863206.2635 - val_loss: 30979846.4000\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7844677.7406 - val_loss: 30909316.0000\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7825684.9564 - val_loss: 30845159.7000\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7807018.6867 - val_loss: 30777923.5000\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7788349.6764 - val_loss: 30710460.5000\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7769529.4364 - val_loss: 30646985.5000\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7751080.6452 - val_loss: 30579071.5000\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7732300.8265 - val_loss: 30512418.1000\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7713724.5416 - val_loss: 30443933.3000\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7695001.1083 - val_loss: 30378916.6000\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7676459.4276 - val_loss: 30311590.5000\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7657840.8752 - val_loss: 30246341.4000\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7639378.8563 - val_loss: 30179058.8000\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7620816.0428 - val_loss: 30113996.8000\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7602424.7147 - val_loss: 30044760.5000\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7583803.6275 - val_loss: 29979643.8000\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7565526.2490 - val_loss: 29912397.7000\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7547010.2553 - val_loss: 29849409.4000\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7528597.4166 - val_loss: 29784195.3000\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7510346.7755 - val_loss: 29714965.2000\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7491807.4973 - val_loss: 29651811.0000\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7473646.0644 - val_loss: 29585496.6000\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7455304.7313 - val_loss: 29519795.0000\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7437011.6920 - val_loss: 29453047.7000\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7418779.5547 - val_loss: 29387024.5000\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7400695.4062 - val_loss: 29320321.9000\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7382277.0912 - val_loss: 29259136.2000\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7364294.3642 - val_loss: 29192409.2000\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7345997.2096 - val_loss: 29129996.5000\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7327974.7351 - val_loss: 29063017.6000\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7309779.9754 - val_loss: 28999319.5000\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7291783.6007 - val_loss: 28933209.5000\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7273625.5434 - val_loss: 28870771.3000\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7255926.1419 - val_loss: 28802781.1000\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7237747.1105 - val_loss: 28737645.5000\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7219704.7062 - val_loss: 28675799.2000\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7201798.5967 - val_loss: 28609520.4000\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7183937.1034 - val_loss: 28543138.8000\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7165837.7298 - val_loss: 28481204.5000\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7148064.4828 - val_loss: 28417268.8000\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7130218.5416 - val_loss: 28353883.8000\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7112443.3347 - val_loss: 28288292.1000\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7094527.0579 - val_loss: 28225524.7000\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7076872.8556 - val_loss: 28160107.0000\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7059024.8616 - val_loss: 28097446.1000\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7041321.7669 - val_loss: 28034297.1000\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7023571.7264 - val_loss: 27970877.6000\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 7005908.7790 - val_loss: 27906796.0000\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6988165.8018 - val_loss: 27844911.0000\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6970541.7229 - val_loss: 27780086.2000\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6953091.1188 - val_loss: 27713375.2000\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6935439.0173 - val_loss: 27650377.5000\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6917755.8933 - val_loss: 27589314.1000\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6900316.0570 - val_loss: 27525917.0000\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6882863.0501 - val_loss: 27460862.4000\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6865239.2044 - val_loss: 27399627.2000\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6847847.6122 - val_loss: 27336564.6000\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6830481.9527 - val_loss: 27273354.1000\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6812982.5821 - val_loss: 27212379.6000\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6795751.3386 - val_loss: 27148331.0000\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6778234.9675 - val_loss: 27087327.8000\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6760949.8683 - val_loss: 27023237.0000\n",
      "Epoch 282/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/sample - loss: 6743583.7679 - val_loss: 26961709.1000\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6726392.3658 - val_loss: 26898441.9000\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6708994.5374 - val_loss: 26838305.4000\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6691874.0313 - val_loss: 26773968.9000\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6674566.0140 - val_loss: 26711391.4000\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6657271.7448 - val_loss: 26650916.7000\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6640160.7542 - val_loss: 26588414.6000\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6622954.3379 - val_loss: 26526670.8000\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6605838.5484 - val_loss: 26464994.3000\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6588714.6154 - val_loss: 26403116.5000\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6571700.3363 - val_loss: 26341296.6000\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6554712.1292 - val_loss: 26279453.1000\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6537677.4073 - val_loss: 26217669.4000\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6520587.0371 - val_loss: 26158104.3000\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6503649.4841 - val_loss: 26095922.9000\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6486683.4760 - val_loss: 26034006.9000\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6469788.3625 - val_loss: 25971831.8000\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6452859.1464 - val_loss: 25910072.0000\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 6435941.2941 - val_loss: 25850726.6000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=2, activation='linear'))\n",
    "# 1: 출력값의 갯수, input_dim=2: 입력 데이터 갯수,\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='mse') \n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs = 300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 파라미터 3개 = 가중치2개 + bias 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 47589162.0000 ]) # 값을 반영하여 변경\n",
    "# val_loss: 1386.4710 오차들의 합\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# 값이 떨어지면 학습이 되고 있다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7568.0\n",
      "7643.0\n",
      "7718.0\n",
      "7793.0\n",
      "7868.0\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과를 테스트\n",
    "x = np.array([[101, 10], [102, 10], [103, 10], [104, 10], [105, 10]])\n",
    "for i in range(len(x)):  # 실제값 비교 목적으로 산출\n",
    "    print((x[i][0] * x[i][1]) / 2 * 5 * 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [101  10], 실제값: 7568, 예측값: 1879.78943, 정제된값: 1880\n",
      "x: [102  10], 실제값: 7643, 예측값: 1896.21008, 정제된값: 1896\n",
      "x: [103  10], 실제값: 7718, 예측값: 1912.63086, 정제된값: 1913\n",
      "x: [104  10], 실제값: 7793, 예측값: 1929.05151, 정제된값: 1929\n",
      "x: [105  10], 실제값: 7868, 예측값: 1945.47229, 정제된값: 1945\n"
     ]
    }
   ],
   "source": [
    "y = np.array([7568, 7643, 7718, 7793, 7868]) # 실제값\n",
    "\n",
    "pd = model.predict(x) # 모델 사용\n",
    "# print(pd.shape)\n",
    "# print(pd)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, 실제값: {1}, 예측값: {2:.5f}, 정제된값: {3:.0f}'\n",
    "    print(fmt.format(x[i], y[i], pd[i][0], pd[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
