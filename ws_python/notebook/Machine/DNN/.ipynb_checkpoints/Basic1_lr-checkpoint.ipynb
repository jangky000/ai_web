{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# DNN: deep neural network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tensorflow 2.0에 내장된 Keras 사용\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용 함수\n",
    "from tensorflow.keras.layers import Dense       # 전결합층\n",
    "from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "\n",
    "# tensorflow 1.x, Keras가 독립적으로 설치된 경우\n",
    "# from keras.models import Sequential  # class\n",
    "# from keras.models import load_model  # model 사용 함수\n",
    "# from keras.layers import Dense       # class\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "\n",
    "# 훈련 데이터: 수\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15,16,17,18,19,20])\n",
    "\n",
    "# 정답 데이터: 배수\n",
    "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론 \n",
    "#### 학습률 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경세포 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 16ms/sample - loss: 164.9182 - val_loss: 542.7130\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 132.9581 - val_loss: 445.8756\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 108.5861 - val_loss: 352.5414\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 84.4784 - val_loss: 281.5023\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 65.9745 - val_loss: 221.4670\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 50.3092 - val_loss: 174.3300\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 38.7041 - val_loss: 132.9926\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 28.2831 - val_loss: 103.6104\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 21.7436 - val_loss: 75.3547\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 15.3107 - val_loss: 56.2332\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 10.9855 - val_loss: 41.7244\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 8.0373 - val_loss: 29.8079\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 5.3549 - val_loss: 22.6359\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 3.7982 - val_loss: 16.9258\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 2.6956 - val_loss: 12.4767\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.9801 - val_loss: 8.8249\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.3557 - val_loss: 6.7248\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 1.0637 - val_loss: 4.9172\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.7927 - val_loss: 3.8437\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.6482 - val_loss: 3.1292\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5686 - val_loss: 2.4612\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.5005 - val_loss: 2.1282\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4642 - val_loss: 1.7930\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4490 - val_loss: 1.4629\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4257 - val_loss: 1.3659\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4155 - val_loss: 1.2136\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.4086 - val_loss: 1.0809\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3989 - val_loss: 1.0964\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3931 - val_loss: 1.0055\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3858 - val_loss: 0.9788\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3821 - val_loss: 0.9659\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3750 - val_loss: 0.9231\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3700 - val_loss: 0.9086\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3635 - val_loss: 0.8505\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3588 - val_loss: 0.8615\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3520 - val_loss: 0.8283\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3464 - val_loss: 0.8132\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3424 - val_loss: 0.8138\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3360 - val_loss: 0.8103\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3292 - val_loss: 0.7631\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3237 - val_loss: 0.7406\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3180 - val_loss: 0.7423\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3154 - val_loss: 0.7803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3090 - val_loss: 0.7249\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.3011 - val_loss: 0.6938\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2969 - val_loss: 0.6616\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2902 - val_loss: 0.6535\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2849 - val_loss: 0.6339\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2805 - val_loss: 0.6760\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2732 - val_loss: 0.6632\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2709 - val_loss: 0.5981\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2664 - val_loss: 0.6533\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2571 - val_loss: 0.5910\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2524 - val_loss: 0.6112\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2462 - val_loss: 0.5575\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2413 - val_loss: 0.5723\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2366 - val_loss: 0.5232\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2349 - val_loss: 0.5812\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2256 - val_loss: 0.5505\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2223 - val_loss: 0.4674\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2157 - val_loss: 0.4907\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2098 - val_loss: 0.4806\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2055 - val_loss: 0.4641\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.2007 - val_loss: 0.4685\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1960 - val_loss: 0.4785\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1912 - val_loss: 0.4290\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1862 - val_loss: 0.4204\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1822 - val_loss: 0.3929\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1763 - val_loss: 0.4171\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1726 - val_loss: 0.4270\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1691 - val_loss: 0.3783\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1639 - val_loss: 0.3803\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1590 - val_loss: 0.3848\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1550 - val_loss: 0.3596\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1511 - val_loss: 0.3655\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1466 - val_loss: 0.3405\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1444 - val_loss: 0.3602\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1381 - val_loss: 0.3186\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1354 - val_loss: 0.2918\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1303 - val_loss: 0.2884\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1267 - val_loss: 0.3032\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1239 - val_loss: 0.3031\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1197 - val_loss: 0.2743\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1159 - val_loss: 0.2666\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1127 - val_loss: 0.2429\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1093 - val_loss: 0.2638\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1059 - val_loss: 0.2349\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.1028 - val_loss: 0.2483\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0987 - val_loss: 0.2298\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0962 - val_loss: 0.2112\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0928 - val_loss: 0.2140\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0899 - val_loss: 0.1952\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0870 - val_loss: 0.2005\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0843 - val_loss: 0.2058\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0816 - val_loss: 0.1857\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0790 - val_loss: 0.1896\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0776 - val_loss: 0.1498\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0736 - val_loss: 0.1598\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0707 - val_loss: 0.1662\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/sample - loss: 0.0683 - val_loss: 0.1690\n"
     ]
    }
   ],
   "source": [
    "# 단순 수치 예측할 때, linear와 mse를 사용한다.\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "# dense: 전결합층을 은닉층으로 추가\n",
    "# 1: 출력값의 갯수, input_dim=1: 입력 데이터 갯수,\n",
    "# activation='linear': 활성화 함수, 선형 회귀 -> ax + b\n",
    "\n",
    "# 학습률 조절\n",
    "# 특정 가중치,bias 변경시 오차 크게 발생할 위험 있음\n",
    "# 학습률 10은 너무 크다 -> 학습 그래프에서 오차의 변동이 크다\n",
    "# model.compile(optimizer=Adam(lr=10.0), loss='mse')\n",
    "# model.compile(optimizer=Adam(lr=0.2), loss='mse')\n",
    "# model.compile(optimizer=Adam(lr=0.1), loss='mse')\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse')\n",
    "\n",
    "# epochs: 20, 50, 100, 300, 1000\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs = 100, batch_size=1)\n",
    "# x_train: 훈련 데이터, y_train: 타깃(실제값), 지도 학습\n",
    "# validation_split=0.2: 훈련과 검증을 80:20으로 데이터 분할\n",
    "# shuffle=True: 데이터 무작위 검증\n",
    "# epochs=30: 전체 데이터 학습 횟수\n",
    "# batch_size=1: 1건 처리후 가중치 변경\n",
    "# 30 * (20 / 1) = 600번 가중치 변경\n",
    "# 30 * (20 / 2) = 300번 가중치 변경\n",
    "# 30 * (20 / 20) = 30번 가중치 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 파라미터 2개 = 가중치1개 + bias 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 2675.0146 ]) # 값을 반영하여 변경\n",
    "# val_loss: 2675.0146 오차들의 합\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# 값이 떨어지면 학습이 되고 있다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "[[ 99.92946 ]\n",
      " [101.87827 ]\n",
      " [103.82709 ]\n",
      " [105.77591 ]\n",
      " [107.724724]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과를 테스트\n",
    "x = np.array([51, 52, 53, 54, 55])\n",
    "y = np.array([102, 104, 106, 108, 110]) # 실제답, 비교 목적\n",
    "\n",
    "pd = model.predict(x) # 모델 사용, 2차원 배열로 예측 결과가 발생\n",
    "print(pd.shape)\n",
    "print(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 51, 실제값: 102, 예측값: 100\n",
      "x: 52, 실제값: 104, 예측값: 102\n",
      "x: 53, 실제값: 106, 예측값: 104\n",
      "x: 54, 실제값: 108, 예측값: 106\n",
      "x: 55, 실제값: 110, 예측값: 108\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)):\n",
    "    fmt = 'x: {0}, 실제값: {1}, 예측값: {2:.0f}'\n",
    "    print(fmt.format(x[i], y[i], pd[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
