{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit 발생 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from tensorflow.keras.models import Sequential      # class\n",
    "from tensorflow.keras.models import load_model      # model 사용\n",
    "from tensorflow.keras.layers import Dense           # 전결합\n",
    "from tensorflow.keras.layers import Dropout         # 노드의 비활성화\n",
    "from tensorflow.keras.callbacks import EarlyStopping # 학습 자동 중지\n",
    "from tensorflow.keras import regularizers   # L1, L2 규제 적용\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold  # K 겹 교차 검증\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)           # 맑은 고딕 폰트 지정\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "# Jupyter에게 matplotlib 그래프를 출력 영역에 표시할 것을 지시하는 명령\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(470, 18)\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('./Survival.csv', delimiter=\",\", dtype=np.float64)\n",
    "# 사망자 삭제를 통한 생존자 비율 조정\n",
    "# data = np.loadtxt('./Survival2.csv', delimiter=\",\", dtype=np.float64)\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 17)\n",
      "(470,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0:17] # 0 ~ 16: 17개\n",
    "print(X.shape)\n",
    "Y = data[:, 17]   # 17: 1개\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 분할을 통한 훈련, 검증, 테스트 데이터의 분리\n",
    "seed = 0\n",
    "# 90%: 분할대기(x_train_all), 10%: 테스트(x_test)\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, Y,\n",
    "                                                          stratify=Y,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=seed)\n",
    "# 약한 Overfit\n",
    "# 나머지 데이터 90%를 분할, 70%: 훈련(x_train), 30%: 검증(x_val)\n",
    "\n",
    "# 강한 Overfit \n",
    "# 나머지 데이터 90%를 분할, 90%: 훈련(x_train), 10%: 검증(x_val)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  stratify=y_train_all,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=seed)\n",
    "\n",
    "print(y_val[0:100])\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 43 samples\n",
      "Epoch 1/1000\n",
      "380/380 [==============================] - 2s 6ms/sample - loss: 0.6749 - accuracy: 0.8053 - val_loss: 0.5031 - val_accuracy: 0.7907\n",
      "Epoch 2/1000\n",
      "380/380 [==============================] - 0s 728us/sample - loss: 0.5141 - accuracy: 0.8342 - val_loss: 0.4337 - val_accuracy: 0.8605\n",
      "Epoch 3/1000\n",
      "380/380 [==============================] - 0s 663us/sample - loss: 0.4624 - accuracy: 0.8395 - val_loss: 0.5034 - val_accuracy: 0.8605\n",
      "Epoch 4/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.4653 - accuracy: 0.8474 - val_loss: 0.4630 - val_accuracy: 0.8605\n",
      "Epoch 5/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.4368 - accuracy: 0.8500 - val_loss: 0.4596 - val_accuracy: 0.8605\n",
      "Epoch 6/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.4549 - accuracy: 0.8395 - val_loss: 0.4214 - val_accuracy: 0.8605\n",
      "Epoch 7/1000\n",
      "380/380 [==============================] - 0s 649us/sample - loss: 0.4601 - accuracy: 0.8500 - val_loss: 0.4320 - val_accuracy: 0.8605\n",
      "Epoch 8/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.4354 - accuracy: 0.8500 - val_loss: 0.4568 - val_accuracy: 0.8605\n",
      "Epoch 9/1000\n",
      "380/380 [==============================] - 0s 655us/sample - loss: 0.4266 - accuracy: 0.8447 - val_loss: 0.4401 - val_accuracy: 0.8605\n",
      "Epoch 10/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4274 - accuracy: 0.8500 - val_loss: 0.4700 - val_accuracy: 0.8605\n",
      "Epoch 11/1000\n",
      "380/380 [==============================] - 0s 652us/sample - loss: 0.4313 - accuracy: 0.8500 - val_loss: 0.4361 - val_accuracy: 0.8605\n",
      "Epoch 12/1000\n",
      "380/380 [==============================] - 0s 680us/sample - loss: 0.4273 - accuracy: 0.8500 - val_loss: 0.4453 - val_accuracy: 0.8605\n",
      "Epoch 13/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4647 - accuracy: 0.8421 - val_loss: 0.4421 - val_accuracy: 0.8605\n",
      "Epoch 14/1000\n",
      "380/380 [==============================] - 0s 658us/sample - loss: 0.4369 - accuracy: 0.8500 - val_loss: 0.4729 - val_accuracy: 0.8605\n",
      "Epoch 15/1000\n",
      "380/380 [==============================] - 0s 663us/sample - loss: 0.4327 - accuracy: 0.8500 - val_loss: 0.4390 - val_accuracy: 0.8605\n",
      "Epoch 16/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.4286 - accuracy: 0.8500 - val_loss: 0.4609 - val_accuracy: 0.8605\n",
      "Epoch 17/1000\n",
      "380/380 [==============================] - 0s 648us/sample - loss: 0.4313 - accuracy: 0.8474 - val_loss: 0.4709 - val_accuracy: 0.8605\n",
      "Epoch 18/1000\n",
      "380/380 [==============================] - 0s 667us/sample - loss: 0.4322 - accuracy: 0.8474 - val_loss: 0.4334 - val_accuracy: 0.8605\n",
      "Epoch 19/1000\n",
      "380/380 [==============================] - 0s 646us/sample - loss: 0.4258 - accuracy: 0.8500 - val_loss: 0.4410 - val_accuracy: 0.8605\n",
      "Epoch 20/1000\n",
      "380/380 [==============================] - 0s 686us/sample - loss: 0.4363 - accuracy: 0.8500 - val_loss: 0.4324 - val_accuracy: 0.8605\n",
      "Epoch 21/1000\n",
      "380/380 [==============================] - 0s 639us/sample - loss: 0.4330 - accuracy: 0.8500 - val_loss: 0.4413 - val_accuracy: 0.8605\n",
      "Epoch 22/1000\n",
      "380/380 [==============================] - 0s 660us/sample - loss: 0.4297 - accuracy: 0.8500 - val_loss: 0.4433 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.4253 - accuracy: 0.8500 - val_loss: 0.4399 - val_accuracy: 0.8605\n",
      "Epoch 24/1000\n",
      "380/380 [==============================] - 0s 662us/sample - loss: 0.4254 - accuracy: 0.8474 - val_loss: 0.4369 - val_accuracy: 0.8605\n",
      "Epoch 25/1000\n",
      "380/380 [==============================] - 0s 641us/sample - loss: 0.4254 - accuracy: 0.8500 - val_loss: 0.4281 - val_accuracy: 0.8605\n",
      "Epoch 26/1000\n",
      "380/380 [==============================] - 0s 643us/sample - loss: 0.4306 - accuracy: 0.8500 - val_loss: 0.4291 - val_accuracy: 0.8605\n",
      "Epoch 27/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.4256 - accuracy: 0.8474 - val_loss: 0.4351 - val_accuracy: 0.8605\n",
      "Epoch 28/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.4200 - accuracy: 0.8500 - val_loss: 0.4320 - val_accuracy: 0.8605\n",
      "Epoch 29/1000\n",
      "380/380 [==============================] - 0s 657us/sample - loss: 0.4311 - accuracy: 0.8500 - val_loss: 0.4375 - val_accuracy: 0.8605\n",
      "Epoch 30/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.4244 - accuracy: 0.8500 - val_loss: 0.5172 - val_accuracy: 0.8605\n",
      "Epoch 31/1000\n",
      "380/380 [==============================] - 0s 632us/sample - loss: 0.4450 - accuracy: 0.8474 - val_loss: 0.4519 - val_accuracy: 0.8605\n",
      "Epoch 32/1000\n",
      "380/380 [==============================] - 0s 636us/sample - loss: 0.4269 - accuracy: 0.8500 - val_loss: 0.4315 - val_accuracy: 0.8605\n",
      "Epoch 33/1000\n",
      "380/380 [==============================] - 0s 733us/sample - loss: 0.4203 - accuracy: 0.8500 - val_loss: 0.4462 - val_accuracy: 0.8605\n",
      "Epoch 34/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.4313 - accuracy: 0.8500 - val_loss: 0.4596 - val_accuracy: 0.8605\n",
      "Epoch 35/1000\n",
      "380/380 [==============================] - 0s 662us/sample - loss: 0.4268 - accuracy: 0.8500 - val_loss: 0.4382 - val_accuracy: 0.8605\n",
      "Epoch 36/1000\n",
      "380/380 [==============================] - 0s 632us/sample - loss: 0.4218 - accuracy: 0.8500 - val_loss: 0.4259 - val_accuracy: 0.8605\n",
      "Epoch 37/1000\n",
      "380/380 [==============================] - 0s 693us/sample - loss: 0.4190 - accuracy: 0.8500 - val_loss: 0.4288 - val_accuracy: 0.8605\n",
      "Epoch 38/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.4202 - accuracy: 0.8500 - val_loss: 0.4304 - val_accuracy: 0.8605\n",
      "Epoch 39/1000\n",
      "380/380 [==============================] - 0s 664us/sample - loss: 0.4155 - accuracy: 0.8500 - val_loss: 0.4299 - val_accuracy: 0.8605\n",
      "Epoch 40/1000\n",
      "380/380 [==============================] - 0s 707us/sample - loss: 0.4187 - accuracy: 0.8500 - val_loss: 0.4440 - val_accuracy: 0.8605\n",
      "Epoch 41/1000\n",
      "380/380 [==============================] - 0s 714us/sample - loss: 0.4288 - accuracy: 0.8500 - val_loss: 0.4379 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "380/380 [==============================] - 0s 649us/sample - loss: 0.4276 - accuracy: 0.8474 - val_loss: 0.4317 - val_accuracy: 0.8605\n",
      "Epoch 43/1000\n",
      "380/380 [==============================] - 0s 712us/sample - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.4772 - val_accuracy: 0.8605\n",
      "Epoch 44/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.4242 - accuracy: 0.8500 - val_loss: 0.4242 - val_accuracy: 0.8605\n",
      "Epoch 45/1000\n",
      "380/380 [==============================] - 0s 659us/sample - loss: 0.4225 - accuracy: 0.8500 - val_loss: 0.4313 - val_accuracy: 0.8605\n",
      "Epoch 46/1000\n",
      "380/380 [==============================] - 0s 710us/sample - loss: 0.4181 - accuracy: 0.8474 - val_loss: 0.4365 - val_accuracy: 0.8605\n",
      "Epoch 47/1000\n",
      "380/380 [==============================] - 0s 662us/sample - loss: 0.4192 - accuracy: 0.8500 - val_loss: 0.4415 - val_accuracy: 0.8605\n",
      "Epoch 48/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4127 - accuracy: 0.8500 - val_loss: 0.4362 - val_accuracy: 0.8605\n",
      "Epoch 49/1000\n",
      "380/380 [==============================] - 0s 640us/sample - loss: 0.4174 - accuracy: 0.8500 - val_loss: 0.4609 - val_accuracy: 0.8140\n",
      "Epoch 50/1000\n",
      "380/380 [==============================] - 0s 648us/sample - loss: 0.4153 - accuracy: 0.8447 - val_loss: 0.4263 - val_accuracy: 0.8605\n",
      "Epoch 51/1000\n",
      "380/380 [==============================] - 0s 676us/sample - loss: 0.4166 - accuracy: 0.8500 - val_loss: 0.4368 - val_accuracy: 0.8372\n",
      "Epoch 52/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.4130 - accuracy: 0.8500 - val_loss: 0.4247 - val_accuracy: 0.8605\n",
      "Epoch 53/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.4077 - accuracy: 0.8474 - val_loss: 0.4668 - val_accuracy: 0.8605\n",
      "Epoch 54/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4168 - accuracy: 0.8500 - val_loss: 0.4572 - val_accuracy: 0.8605\n",
      "Epoch 55/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.4191 - accuracy: 0.8500 - val_loss: 0.4376 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "380/380 [==============================] - 0s 729us/sample - loss: 0.4057 - accuracy: 0.8474 - val_loss: 0.4437 - val_accuracy: 0.8605\n",
      "Epoch 57/1000\n",
      "380/380 [==============================] - 0s 771us/sample - loss: 0.4201 - accuracy: 0.8500 - val_loss: 0.4446 - val_accuracy: 0.8605\n",
      "Epoch 58/1000\n",
      "380/380 [==============================] - 0s 1ms/sample - loss: 0.4106 - accuracy: 0.8500 - val_loss: 0.4277 - val_accuracy: 0.8605\n",
      "Epoch 59/1000\n",
      "380/380 [==============================] - 0s 713us/sample - loss: 0.4041 - accuracy: 0.8447 - val_loss: 0.4449 - val_accuracy: 0.8605\n",
      "Epoch 60/1000\n",
      "380/380 [==============================] - 0s 664us/sample - loss: 0.4132 - accuracy: 0.8500 - val_loss: 0.4438 - val_accuracy: 0.8605\n",
      "Epoch 61/1000\n",
      "380/380 [==============================] - 0s 639us/sample - loss: 0.4086 - accuracy: 0.8500 - val_loss: 0.4327 - val_accuracy: 0.8605\n",
      "Epoch 62/1000\n",
      "380/380 [==============================] - 0s 717us/sample - loss: 0.4079 - accuracy: 0.8500 - val_loss: 0.4331 - val_accuracy: 0.8605\n",
      "Epoch 63/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.4031 - accuracy: 0.8526 - val_loss: 0.4308 - val_accuracy: 0.8605\n",
      "Epoch 64/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.4071 - accuracy: 0.8500 - val_loss: 0.4353 - val_accuracy: 0.8605\n",
      "Epoch 65/1000\n",
      "380/380 [==============================] - 0s 638us/sample - loss: 0.4049 - accuracy: 0.8447 - val_loss: 0.4298 - val_accuracy: 0.8605\n",
      "Epoch 66/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4100 - accuracy: 0.8474 - val_loss: 0.4596 - val_accuracy: 0.8372\n",
      "Epoch 67/1000\n",
      "380/380 [==============================] - 0s 736us/sample - loss: 0.4048 - accuracy: 0.8500 - val_loss: 0.4433 - val_accuracy: 0.8605\n",
      "Epoch 68/1000\n",
      "380/380 [==============================] - 0s 1ms/sample - loss: 0.3986 - accuracy: 0.8579 - val_loss: 0.4518 - val_accuracy: 0.8140\n",
      "Epoch 69/1000\n",
      "380/380 [==============================] - 0s 740us/sample - loss: 0.4004 - accuracy: 0.8500 - val_loss: 0.4765 - val_accuracy: 0.8372\n",
      "Epoch 70/1000\n",
      "380/380 [==============================] - 0s 820us/sample - loss: 0.3916 - accuracy: 0.8553 - val_loss: 0.4483 - val_accuracy: 0.8140\n",
      "Epoch 71/1000\n",
      "380/380 [==============================] - 0s 638us/sample - loss: 0.3905 - accuracy: 0.8500 - val_loss: 0.4530 - val_accuracy: 0.8372\n",
      "Epoch 72/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3895 - accuracy: 0.8553 - val_loss: 0.4498 - val_accuracy: 0.8140\n",
      "Epoch 73/1000\n",
      "380/380 [==============================] - 0s 633us/sample - loss: 0.4048 - accuracy: 0.8553 - val_loss: 0.4436 - val_accuracy: 0.8140\n",
      "Epoch 74/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3897 - accuracy: 0.8658 - val_loss: 0.4750 - val_accuracy: 0.8605\n",
      "Epoch 75/1000\n",
      "380/380 [==============================] - 0s 658us/sample - loss: 0.4003 - accuracy: 0.8553 - val_loss: 0.4474 - val_accuracy: 0.8140\n",
      "Epoch 76/1000\n",
      "380/380 [==============================] - 0s 671us/sample - loss: 0.3867 - accuracy: 0.8632 - val_loss: 0.4846 - val_accuracy: 0.8372\n",
      "Epoch 77/1000\n",
      "380/380 [==============================] - 0s 664us/sample - loss: 0.3958 - accuracy: 0.8579 - val_loss: 0.4457 - val_accuracy: 0.8372\n",
      "Epoch 78/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3903 - accuracy: 0.8579 - val_loss: 0.4599 - val_accuracy: 0.8140\n",
      "Epoch 79/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3871 - accuracy: 0.8658 - val_loss: 0.4396 - val_accuracy: 0.8605\n",
      "Epoch 80/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.3910 - accuracy: 0.8500 - val_loss: 0.4410 - val_accuracy: 0.8605\n",
      "Epoch 81/1000\n",
      "380/380 [==============================] - 0s 630us/sample - loss: 0.4048 - accuracy: 0.8579 - val_loss: 0.4149 - val_accuracy: 0.8605\n",
      "Epoch 82/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.4050 - accuracy: 0.8526 - val_loss: 0.4792 - val_accuracy: 0.7907\n",
      "Epoch 83/1000\n",
      "380/380 [==============================] - 0s 660us/sample - loss: 0.3949 - accuracy: 0.8526 - val_loss: 0.5165 - val_accuracy: 0.7674\n",
      "Epoch 84/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.3846 - accuracy: 0.8658 - val_loss: 0.4898 - val_accuracy: 0.8605\n",
      "Epoch 85/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3812 - accuracy: 0.8632 - val_loss: 0.4413 - val_accuracy: 0.8140\n",
      "Epoch 86/1000\n",
      "380/380 [==============================] - 0s 705us/sample - loss: 0.3828 - accuracy: 0.8553 - val_loss: 0.4401 - val_accuracy: 0.8605\n",
      "Epoch 87/1000\n",
      "380/380 [==============================] - 0s 650us/sample - loss: 0.3703 - accuracy: 0.8684 - val_loss: 0.4708 - val_accuracy: 0.8605\n",
      "Epoch 88/1000\n",
      "380/380 [==============================] - 0s 676us/sample - loss: 0.3787 - accuracy: 0.8632 - val_loss: 0.4719 - val_accuracy: 0.8372\n",
      "Epoch 89/1000\n",
      "380/380 [==============================] - 0s 727us/sample - loss: 0.3845 - accuracy: 0.8579 - val_loss: 0.4422 - val_accuracy: 0.8372\n",
      "Epoch 90/1000\n",
      "380/380 [==============================] - 0s 635us/sample - loss: 0.3785 - accuracy: 0.8553 - val_loss: 0.4397 - val_accuracy: 0.8605\n",
      "Epoch 91/1000\n",
      "380/380 [==============================] - 0s 615us/sample - loss: 0.3803 - accuracy: 0.8579 - val_loss: 0.4614 - val_accuracy: 0.8605\n",
      "Epoch 92/1000\n",
      "380/380 [==============================] - 0s 659us/sample - loss: 0.3776 - accuracy: 0.8526 - val_loss: 0.5187 - val_accuracy: 0.8605\n",
      "Epoch 93/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.3735 - accuracy: 0.8658 - val_loss: 0.4844 - val_accuracy: 0.8140\n",
      "Epoch 94/1000\n",
      "380/380 [==============================] - 0s 662us/sample - loss: 0.3829 - accuracy: 0.8605 - val_loss: 0.4594 - val_accuracy: 0.8140\n",
      "Epoch 95/1000\n",
      "380/380 [==============================] - 0s 755us/sample - loss: 0.3721 - accuracy: 0.8658 - val_loss: 0.4634 - val_accuracy: 0.8605\n",
      "Epoch 96/1000\n",
      "380/380 [==============================] - 0s 664us/sample - loss: 0.3689 - accuracy: 0.8658 - val_loss: 0.4882 - val_accuracy: 0.8605\n",
      "Epoch 97/1000\n",
      "380/380 [==============================] - 0s 762us/sample - loss: 0.3610 - accuracy: 0.8553 - val_loss: 0.5377 - val_accuracy: 0.8372\n",
      "Epoch 98/1000\n",
      "380/380 [==============================] - 0s 727us/sample - loss: 0.3826 - accuracy: 0.8658 - val_loss: 0.4671 - val_accuracy: 0.8605\n",
      "Epoch 99/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3751 - accuracy: 0.8632 - val_loss: 0.4875 - val_accuracy: 0.8140\n",
      "Epoch 100/1000\n",
      "380/380 [==============================] - 0s 643us/sample - loss: 0.3675 - accuracy: 0.8658 - val_loss: 0.4587 - val_accuracy: 0.8140\n",
      "Epoch 101/1000\n",
      "380/380 [==============================] - 0s 757us/sample - loss: 0.3708 - accuracy: 0.8632 - val_loss: 0.6293 - val_accuracy: 0.7674\n",
      "Epoch 102/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3660 - accuracy: 0.8684 - val_loss: 0.4724 - val_accuracy: 0.8605\n",
      "Epoch 103/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.3754 - accuracy: 0.8632 - val_loss: 0.5138 - val_accuracy: 0.7674\n",
      "Epoch 104/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.3582 - accuracy: 0.8658 - val_loss: 0.5392 - val_accuracy: 0.7674\n",
      "Epoch 105/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.3630 - accuracy: 0.8658 - val_loss: 0.5328 - val_accuracy: 0.7674\n",
      "Epoch 106/1000\n",
      "380/380 [==============================] - 0s 621us/sample - loss: 0.3772 - accuracy: 0.8605 - val_loss: 0.4431 - val_accuracy: 0.8372\n",
      "Epoch 107/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.3586 - accuracy: 0.8684 - val_loss: 0.5937 - val_accuracy: 0.7674\n",
      "Epoch 108/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.3643 - accuracy: 0.8684 - val_loss: 0.4435 - val_accuracy: 0.8372\n",
      "Epoch 109/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3435 - accuracy: 0.8684 - val_loss: 0.5092 - val_accuracy: 0.7907\n",
      "Epoch 110/1000\n",
      "380/380 [==============================] - 0s 701us/sample - loss: 0.3541 - accuracy: 0.8684 - val_loss: 0.5227 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "380/380 [==============================] - 0s 667us/sample - loss: 0.3638 - accuracy: 0.8684 - val_loss: 0.5492 - val_accuracy: 0.7907\n",
      "Epoch 112/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3584 - accuracy: 0.8684 - val_loss: 0.5136 - val_accuracy: 0.8140\n",
      "Epoch 113/1000\n",
      "380/380 [==============================] - 0s 690us/sample - loss: 0.3497 - accuracy: 0.8763 - val_loss: 0.7276 - val_accuracy: 0.7442\n",
      "Epoch 114/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.3477 - accuracy: 0.8711 - val_loss: 0.4935 - val_accuracy: 0.8372\n",
      "Epoch 115/1000\n",
      "380/380 [==============================] - 0s 669us/sample - loss: 0.3483 - accuracy: 0.8763 - val_loss: 0.5104 - val_accuracy: 0.8372\n",
      "Epoch 116/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3704 - accuracy: 0.8711 - val_loss: 0.6573 - val_accuracy: 0.7442\n",
      "Epoch 117/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3505 - accuracy: 0.8711 - val_loss: 0.4745 - val_accuracy: 0.8372\n",
      "Epoch 118/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.3403 - accuracy: 0.8763 - val_loss: 0.5459 - val_accuracy: 0.8372\n",
      "Epoch 119/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3426 - accuracy: 0.8711 - val_loss: 0.6459 - val_accuracy: 0.8140\n",
      "Epoch 120/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.3399 - accuracy: 0.8737 - val_loss: 0.6535 - val_accuracy: 0.7674\n",
      "Epoch 121/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3287 - accuracy: 0.8763 - val_loss: 0.6924 - val_accuracy: 0.7674\n",
      "Epoch 122/1000\n",
      "380/380 [==============================] - 0s 655us/sample - loss: 0.3419 - accuracy: 0.8684 - val_loss: 0.9257 - val_accuracy: 0.7442\n",
      "Epoch 123/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3474 - accuracy: 0.8632 - val_loss: 0.6342 - val_accuracy: 0.8140\n",
      "Epoch 124/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.3596 - accuracy: 0.8737 - val_loss: 0.5201 - val_accuracy: 0.8372\n",
      "Epoch 125/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3376 - accuracy: 0.8711 - val_loss: 0.6470 - val_accuracy: 0.7907\n",
      "Epoch 126/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3496 - accuracy: 0.8684 - val_loss: 0.5759 - val_accuracy: 0.7674\n",
      "Epoch 127/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.3589 - accuracy: 0.8632 - val_loss: 0.6429 - val_accuracy: 0.7674\n",
      "Epoch 128/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3315 - accuracy: 0.8763 - val_loss: 0.6225 - val_accuracy: 0.8140\n",
      "Epoch 129/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.3475 - accuracy: 0.8632 - val_loss: 0.5446 - val_accuracy: 0.7907\n",
      "Epoch 130/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3614 - accuracy: 0.8658 - val_loss: 0.5023 - val_accuracy: 0.7907\n",
      "Epoch 131/1000\n",
      "380/380 [==============================] - 0s 669us/sample - loss: 0.3321 - accuracy: 0.8737 - val_loss: 0.5223 - val_accuracy: 0.7674\n",
      "Epoch 132/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3686 - accuracy: 0.8737 - val_loss: 0.6472 - val_accuracy: 0.8140\n",
      "Epoch 133/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3576 - accuracy: 0.8632 - val_loss: 0.5024 - val_accuracy: 0.8372\n",
      "Epoch 134/1000\n",
      "380/380 [==============================] - 0s 704us/sample - loss: 0.3482 - accuracy: 0.8711 - val_loss: 0.4671 - val_accuracy: 0.8140\n",
      "Epoch 135/1000\n",
      "380/380 [==============================] - 0s 656us/sample - loss: 0.3392 - accuracy: 0.8658 - val_loss: 0.7301 - val_accuracy: 0.7442\n",
      "Epoch 136/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.3253 - accuracy: 0.8737 - val_loss: 1.0496 - val_accuracy: 0.7674\n",
      "Epoch 137/1000\n",
      "380/380 [==============================] - 0s 686us/sample - loss: 0.3362 - accuracy: 0.8684 - val_loss: 0.5900 - val_accuracy: 0.8140\n",
      "Epoch 138/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3394 - accuracy: 0.8632 - val_loss: 0.6911 - val_accuracy: 0.8140\n",
      "Epoch 139/1000\n",
      "380/380 [==============================] - 0s 665us/sample - loss: 0.3296 - accuracy: 0.8816 - val_loss: 1.1584 - val_accuracy: 0.7442\n",
      "Epoch 140/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.3449 - accuracy: 0.8632 - val_loss: 0.7948 - val_accuracy: 0.7674\n",
      "Epoch 141/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.3274 - accuracy: 0.8789 - val_loss: 0.7976 - val_accuracy: 0.7442\n",
      "Epoch 142/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3636 - accuracy: 0.8763 - val_loss: 0.4343 - val_accuracy: 0.8605\n",
      "Epoch 143/1000\n",
      "380/380 [==============================] - 0s 704us/sample - loss: 0.3374 - accuracy: 0.8684 - val_loss: 0.4964 - val_accuracy: 0.8140\n",
      "Epoch 144/1000\n",
      "380/380 [==============================] - 0s 676us/sample - loss: 0.3326 - accuracy: 0.8789 - val_loss: 0.5462 - val_accuracy: 0.8140\n",
      "Epoch 145/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.3202 - accuracy: 0.8789 - val_loss: 0.5895 - val_accuracy: 0.8140\n",
      "Epoch 146/1000\n",
      "380/380 [==============================] - 0s 644us/sample - loss: 0.4030 - accuracy: 0.8711 - val_loss: 0.5154 - val_accuracy: 0.7907\n",
      "Epoch 147/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.3220 - accuracy: 0.8816 - val_loss: 0.5895 - val_accuracy: 0.7442\n",
      "Epoch 148/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.3302 - accuracy: 0.8789 - val_loss: 0.4833 - val_accuracy: 0.8140\n",
      "Epoch 149/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3343 - accuracy: 0.8711 - val_loss: 0.9355 - val_accuracy: 0.7442\n",
      "Epoch 150/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.3366 - accuracy: 0.8763 - val_loss: 0.4499 - val_accuracy: 0.7907\n",
      "Epoch 151/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3375 - accuracy: 0.8763 - val_loss: 0.4647 - val_accuracy: 0.8140\n",
      "Epoch 152/1000\n",
      "380/380 [==============================] - 0s 667us/sample - loss: 0.3201 - accuracy: 0.8789 - val_loss: 0.6488 - val_accuracy: 0.7442\n",
      "Epoch 153/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.3233 - accuracy: 0.8816 - val_loss: 0.5946 - val_accuracy: 0.7907\n",
      "Epoch 154/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.3178 - accuracy: 0.8816 - val_loss: 1.2689 - val_accuracy: 0.7209\n",
      "Epoch 155/1000\n",
      "380/380 [==============================] - 0s 645us/sample - loss: 0.3348 - accuracy: 0.8711 - val_loss: 0.6123 - val_accuracy: 0.7442\n",
      "Epoch 156/1000\n",
      "380/380 [==============================] - 0s 710us/sample - loss: 0.3316 - accuracy: 0.8737 - val_loss: 0.5376 - val_accuracy: 0.7674\n",
      "Epoch 157/1000\n",
      "380/380 [==============================] - 0s 661us/sample - loss: 0.3072 - accuracy: 0.8868 - val_loss: 0.6574 - val_accuracy: 0.7907\n",
      "Epoch 158/1000\n",
      "380/380 [==============================] - 0s 667us/sample - loss: 0.3082 - accuracy: 0.8816 - val_loss: 0.4444 - val_accuracy: 0.8372\n",
      "Epoch 159/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3175 - accuracy: 0.8868 - val_loss: 0.4241 - val_accuracy: 0.8140\n",
      "Epoch 160/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3325 - accuracy: 0.8789 - val_loss: 0.5951 - val_accuracy: 0.7674\n",
      "Epoch 161/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3320 - accuracy: 0.8763 - val_loss: 0.4751 - val_accuracy: 0.8140\n",
      "Epoch 162/1000\n",
      "380/380 [==============================] - 0s 642us/sample - loss: 0.3325 - accuracy: 0.8737 - val_loss: 0.8296 - val_accuracy: 0.7442\n",
      "Epoch 163/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3334 - accuracy: 0.8711 - val_loss: 0.5003 - val_accuracy: 0.8140\n",
      "Epoch 164/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.3279 - accuracy: 0.8816 - val_loss: 0.7629 - val_accuracy: 0.7442\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 665us/sample - loss: 0.3239 - accuracy: 0.8842 - val_loss: 0.8201 - val_accuracy: 0.7442\n",
      "Epoch 166/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.3260 - accuracy: 0.8711 - val_loss: 0.4808 - val_accuracy: 0.8140\n",
      "Epoch 167/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3092 - accuracy: 0.8816 - val_loss: 0.8374 - val_accuracy: 0.7442\n",
      "Epoch 168/1000\n",
      "380/380 [==============================] - 0s 666us/sample - loss: 0.3130 - accuracy: 0.8789 - val_loss: 0.5019 - val_accuracy: 0.8140\n",
      "Epoch 169/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.3471 - accuracy: 0.8737 - val_loss: 0.6211 - val_accuracy: 0.7442\n",
      "Epoch 170/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.3079 - accuracy: 0.8816 - val_loss: 0.5100 - val_accuracy: 0.7674\n",
      "Epoch 171/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.3130 - accuracy: 0.8789 - val_loss: 0.8056 - val_accuracy: 0.7442\n",
      "Epoch 172/1000\n",
      "380/380 [==============================] - 0s 696us/sample - loss: 0.3168 - accuracy: 0.8789 - val_loss: 0.6967 - val_accuracy: 0.7674\n",
      "Epoch 173/1000\n",
      "380/380 [==============================] - 0s 654us/sample - loss: 0.2931 - accuracy: 0.8816 - val_loss: 0.7196 - val_accuracy: 0.7907\n",
      "Epoch 174/1000\n",
      "380/380 [==============================] - 0s 650us/sample - loss: 0.2994 - accuracy: 0.8921 - val_loss: 1.2558 - val_accuracy: 0.7674\n",
      "Epoch 175/1000\n",
      "380/380 [==============================] - 0s 703us/sample - loss: 0.3037 - accuracy: 0.8921 - val_loss: 0.7463 - val_accuracy: 0.7674\n",
      "Epoch 176/1000\n",
      "380/380 [==============================] - 0s 662us/sample - loss: 0.3116 - accuracy: 0.8842 - val_loss: 0.5305 - val_accuracy: 0.8372\n",
      "Epoch 177/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3366 - accuracy: 0.8737 - val_loss: 0.5785 - val_accuracy: 0.8372\n",
      "Epoch 178/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3145 - accuracy: 0.8842 - val_loss: 0.6550 - val_accuracy: 0.8372\n",
      "Epoch 179/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3098 - accuracy: 0.8789 - val_loss: 0.7790 - val_accuracy: 0.7674\n",
      "Epoch 180/1000\n",
      "380/380 [==============================] - 0s 663us/sample - loss: 0.3298 - accuracy: 0.8816 - val_loss: 0.5211 - val_accuracy: 0.8140\n",
      "Epoch 181/1000\n",
      "380/380 [==============================] - 0s 639us/sample - loss: 0.3230 - accuracy: 0.8868 - val_loss: 0.9591 - val_accuracy: 0.7442\n",
      "Epoch 182/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3166 - accuracy: 0.8842 - val_loss: 0.5127 - val_accuracy: 0.7674\n",
      "Epoch 183/1000\n",
      "380/380 [==============================] - 0s 666us/sample - loss: 0.3140 - accuracy: 0.8842 - val_loss: 0.7073 - val_accuracy: 0.7907\n",
      "Epoch 184/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.3062 - accuracy: 0.8842 - val_loss: 0.6388 - val_accuracy: 0.7674\n",
      "Epoch 185/1000\n",
      "380/380 [==============================] - 0s 664us/sample - loss: 0.3175 - accuracy: 0.8895 - val_loss: 0.7429 - val_accuracy: 0.7442\n",
      "Epoch 186/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3030 - accuracy: 0.8921 - val_loss: 2.1362 - val_accuracy: 0.7674\n",
      "Epoch 187/1000\n",
      "380/380 [==============================] - 0s 680us/sample - loss: 0.3259 - accuracy: 0.8842 - val_loss: 0.7082 - val_accuracy: 0.7907\n",
      "Epoch 188/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.2945 - accuracy: 0.8921 - val_loss: 1.3751 - val_accuracy: 0.7674\n",
      "Epoch 189/1000\n",
      "380/380 [==============================] - 0s 637us/sample - loss: 0.3144 - accuracy: 0.8789 - val_loss: 0.8376 - val_accuracy: 0.7442\n",
      "Epoch 190/1000\n",
      "380/380 [==============================] - 0s 636us/sample - loss: 0.3209 - accuracy: 0.8789 - val_loss: 0.6510 - val_accuracy: 0.7907\n",
      "Epoch 191/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.3217 - accuracy: 0.8763 - val_loss: 0.5109 - val_accuracy: 0.8140\n",
      "Epoch 192/1000\n",
      "380/380 [==============================] - 0s 671us/sample - loss: 0.3020 - accuracy: 0.8868 - val_loss: 0.9454 - val_accuracy: 0.7907\n",
      "Epoch 193/1000\n",
      "380/380 [==============================] - 0s 706us/sample - loss: 0.3000 - accuracy: 0.8921 - val_loss: 1.1739 - val_accuracy: 0.7674\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "model.add(Dense(128, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 최소 오차 20번 나오면 자동 종료\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "# 학습\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                 epochs=1000, \n",
    "                 batch_size=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 43 samples\n",
      "Epoch 1/1000\n",
      "380/380 [==============================] - 1s 2ms/sample - loss: 0.7102 - accuracy: 0.7921 - val_loss: 0.4342 - val_accuracy: 0.8605\n",
      "Epoch 2/1000\n",
      "380/380 [==============================] - 0s 715us/sample - loss: 0.4322 - accuracy: 0.8500 - val_loss: 0.4255 - val_accuracy: 0.8605\n",
      "Epoch 3/1000\n",
      "380/380 [==============================] - 0s 731us/sample - loss: 0.4413 - accuracy: 0.8500 - val_loss: 0.4419 - val_accuracy: 0.8605\n",
      "Epoch 4/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.4347 - accuracy: 0.8500 - val_loss: 0.4250 - val_accuracy: 0.8605\n",
      "Epoch 5/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4311 - accuracy: 0.8500 - val_loss: 0.4308 - val_accuracy: 0.8605\n",
      "Epoch 6/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.4355 - accuracy: 0.8500 - val_loss: 0.4312 - val_accuracy: 0.8605\n",
      "Epoch 7/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.5058 - accuracy: 0.8211 - val_loss: 0.4842 - val_accuracy: 0.8605\n",
      "Epoch 8/1000\n",
      "380/380 [==============================] - 0s 693us/sample - loss: 0.4369 - accuracy: 0.8500 - val_loss: 0.4432 - val_accuracy: 0.8605\n",
      "Epoch 9/1000\n",
      "380/380 [==============================] - 0s 668us/sample - loss: 0.4330 - accuracy: 0.8500 - val_loss: 0.4378 - val_accuracy: 0.8605\n",
      "Epoch 10/1000\n",
      "380/380 [==============================] - 0s 701us/sample - loss: 0.4285 - accuracy: 0.8500 - val_loss: 0.4287 - val_accuracy: 0.8605\n",
      "Epoch 11/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4351 - accuracy: 0.8500 - val_loss: 0.4354 - val_accuracy: 0.8605\n",
      "Epoch 12/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.4222 - accuracy: 0.8500 - val_loss: 0.4852 - val_accuracy: 0.8605\n",
      "Epoch 13/1000\n",
      "380/380 [==============================] - 0s 704us/sample - loss: 0.4249 - accuracy: 0.8500 - val_loss: 0.4388 - val_accuracy: 0.8605\n",
      "Epoch 14/1000\n",
      "380/380 [==============================] - 0s 661us/sample - loss: 0.4258 - accuracy: 0.8500 - val_loss: 0.4333 - val_accuracy: 0.8605\n",
      "Epoch 15/1000\n",
      "380/380 [==============================] - 0s 727us/sample - loss: 0.4303 - accuracy: 0.8500 - val_loss: 0.4569 - val_accuracy: 0.8605\n",
      "Epoch 16/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.4301 - accuracy: 0.8500 - val_loss: 0.4407 - val_accuracy: 0.8605\n",
      "Epoch 17/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.4399 - accuracy: 0.8500 - val_loss: 0.4266 - val_accuracy: 0.8605\n",
      "Epoch 18/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.4272 - accuracy: 0.8500 - val_loss: 0.4337 - val_accuracy: 0.8605\n",
      "Epoch 19/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.4225 - accuracy: 0.8500 - val_loss: 0.4317 - val_accuracy: 0.8605\n",
      "Epoch 20/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.4307 - accuracy: 0.8500 - val_loss: 0.4293 - val_accuracy: 0.8605\n",
      "Epoch 21/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.4281 - accuracy: 0.8500 - val_loss: 0.4378 - val_accuracy: 0.8605\n",
      "Epoch 22/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4301 - accuracy: 0.8500 - val_loss: 0.4290 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4218 - accuracy: 0.8500 - val_loss: 0.4319 - val_accuracy: 0.8605\n",
      "Epoch 24/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4238 - accuracy: 0.8500 - val_loss: 0.4482 - val_accuracy: 0.8605\n",
      "Epoch 25/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.4310 - accuracy: 0.8500 - val_loss: 0.4331 - val_accuracy: 0.8605\n",
      "Epoch 26/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4273 - accuracy: 0.8500 - val_loss: 0.4267 - val_accuracy: 0.8605\n",
      "Epoch 27/1000\n",
      "380/380 [==============================] - 0s 686us/sample - loss: 0.4259 - accuracy: 0.8500 - val_loss: 0.4357 - val_accuracy: 0.8605\n",
      "Epoch 28/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.4282 - val_accuracy: 0.8605\n",
      "Epoch 29/1000\n",
      "380/380 [==============================] - 0s 657us/sample - loss: 0.4253 - accuracy: 0.8500 - val_loss: 0.4275 - val_accuracy: 0.8605\n",
      "Epoch 30/1000\n",
      "380/380 [==============================] - 0s 703us/sample - loss: 0.4236 - accuracy: 0.8500 - val_loss: 0.4349 - val_accuracy: 0.8605\n",
      "Epoch 31/1000\n",
      "380/380 [==============================] - 0s 701us/sample - loss: 0.4253 - accuracy: 0.8500 - val_loss: 0.4344 - val_accuracy: 0.8605\n",
      "Epoch 32/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4211 - accuracy: 0.8500 - val_loss: 0.4459 - val_accuracy: 0.8605\n",
      "Epoch 33/1000\n",
      "380/380 [==============================] - 0s 696us/sample - loss: 0.4185 - accuracy: 0.8500 - val_loss: 0.4269 - val_accuracy: 0.8605\n",
      "Epoch 34/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.4189 - accuracy: 0.8500 - val_loss: 0.4385 - val_accuracy: 0.8605\n",
      "Epoch 35/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.4289 - accuracy: 0.8500 - val_loss: 0.4319 - val_accuracy: 0.8605\n",
      "Epoch 36/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4183 - accuracy: 0.8500 - val_loss: 0.4250 - val_accuracy: 0.8605\n",
      "Epoch 37/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4297 - accuracy: 0.8500 - val_loss: 0.4323 - val_accuracy: 0.8605\n",
      "Epoch 38/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4229 - accuracy: 0.8500 - val_loss: 0.4381 - val_accuracy: 0.8605\n",
      "Epoch 39/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.4160 - accuracy: 0.8500 - val_loss: 0.4452 - val_accuracy: 0.8605\n",
      "Epoch 40/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.4232 - accuracy: 0.8500 - val_loss: 0.4289 - val_accuracy: 0.8605\n",
      "Epoch 41/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.4279 - accuracy: 0.8421 - val_loss: 0.4277 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "380/380 [==============================] - 0s 686us/sample - loss: 0.4210 - accuracy: 0.8500 - val_loss: 0.4256 - val_accuracy: 0.8605\n",
      "Epoch 43/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.4205 - accuracy: 0.8500 - val_loss: 0.4275 - val_accuracy: 0.8605\n",
      "Epoch 44/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.4190 - accuracy: 0.8500 - val_loss: 0.4276 - val_accuracy: 0.8605\n",
      "Epoch 45/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.4220 - accuracy: 0.8500 - val_loss: 0.4245 - val_accuracy: 0.8605\n",
      "Epoch 46/1000\n",
      "380/380 [==============================] - 0s 724us/sample - loss: 0.4126 - accuracy: 0.8500 - val_loss: 0.4345 - val_accuracy: 0.8605\n",
      "Epoch 47/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.4157 - accuracy: 0.8500 - val_loss: 0.4232 - val_accuracy: 0.8605\n",
      "Epoch 48/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.4223 - accuracy: 0.8500 - val_loss: 0.4261 - val_accuracy: 0.8605\n",
      "Epoch 49/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4150 - accuracy: 0.8474 - val_loss: 0.4761 - val_accuracy: 0.8140\n",
      "Epoch 50/1000\n",
      "380/380 [==============================] - 0s 729us/sample - loss: 0.4162 - accuracy: 0.8500 - val_loss: 0.4441 - val_accuracy: 0.8605\n",
      "Epoch 51/1000\n",
      "380/380 [==============================] - 0s 688us/sample - loss: 0.4154 - accuracy: 0.8500 - val_loss: 0.4269 - val_accuracy: 0.8605\n",
      "Epoch 52/1000\n",
      "380/380 [==============================] - 0s 740us/sample - loss: 0.4223 - accuracy: 0.8500 - val_loss: 0.4327 - val_accuracy: 0.8605\n",
      "Epoch 53/1000\n",
      "380/380 [==============================] - 0s 690us/sample - loss: 0.4126 - accuracy: 0.8500 - val_loss: 0.4267 - val_accuracy: 0.8605\n",
      "Epoch 54/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4103 - accuracy: 0.8500 - val_loss: 0.4489 - val_accuracy: 0.8605\n",
      "Epoch 55/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.4076 - accuracy: 0.8474 - val_loss: 0.4358 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "380/380 [==============================] - 0s 661us/sample - loss: 0.4097 - accuracy: 0.8447 - val_loss: 0.4346 - val_accuracy: 0.8605\n",
      "Epoch 57/1000\n",
      "380/380 [==============================] - 0s 631us/sample - loss: 0.4100 - accuracy: 0.8500 - val_loss: 0.4217 - val_accuracy: 0.8605\n",
      "Epoch 58/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.4141 - accuracy: 0.8500 - val_loss: 0.4297 - val_accuracy: 0.8605\n",
      "Epoch 59/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.4118 - accuracy: 0.8500 - val_loss: 0.4212 - val_accuracy: 0.8605\n",
      "Epoch 60/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.4094 - accuracy: 0.8500 - val_loss: 0.4240 - val_accuracy: 0.8605\n",
      "Epoch 61/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.4083 - accuracy: 0.8500 - val_loss: 0.4313 - val_accuracy: 0.8605\n",
      "Epoch 62/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.4093 - accuracy: 0.8500 - val_loss: 0.4402 - val_accuracy: 0.8605\n",
      "Epoch 63/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.4141 - accuracy: 0.8500 - val_loss: 0.4276 - val_accuracy: 0.8605\n",
      "Epoch 64/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.4065 - accuracy: 0.8500 - val_loss: 0.4196 - val_accuracy: 0.8605\n",
      "Epoch 65/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.4070 - accuracy: 0.8526 - val_loss: 0.4523 - val_accuracy: 0.8605\n",
      "Epoch 66/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4029 - accuracy: 0.8500 - val_loss: 0.4379 - val_accuracy: 0.8605\n",
      "Epoch 67/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.3998 - accuracy: 0.8500 - val_loss: 0.4346 - val_accuracy: 0.8605\n",
      "Epoch 68/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.3995 - accuracy: 0.8500 - val_loss: 0.4299 - val_accuracy: 0.8605\n",
      "Epoch 69/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.3994 - accuracy: 0.8526 - val_loss: 0.4431 - val_accuracy: 0.8605\n",
      "Epoch 70/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4033 - accuracy: 0.8474 - val_loss: 0.4274 - val_accuracy: 0.8605\n",
      "Epoch 71/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3968 - accuracy: 0.8500 - val_loss: 0.4703 - val_accuracy: 0.8605\n",
      "Epoch 72/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.4015 - accuracy: 0.8526 - val_loss: 0.4335 - val_accuracy: 0.8605\n",
      "Epoch 73/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3917 - accuracy: 0.8605 - val_loss: 0.4792 - val_accuracy: 0.8605\n",
      "Epoch 74/1000\n",
      "380/380 [==============================] - 0s 669us/sample - loss: 0.4034 - accuracy: 0.8605 - val_loss: 0.4326 - val_accuracy: 0.8605\n",
      "Epoch 75/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.3976 - accuracy: 0.8500 - val_loss: 0.4384 - val_accuracy: 0.8605\n",
      "Epoch 76/1000\n",
      "380/380 [==============================] - 0s 720us/sample - loss: 0.3984 - accuracy: 0.8526 - val_loss: 0.4576 - val_accuracy: 0.8605\n",
      "Epoch 77/1000\n",
      "380/380 [==============================] - 0s 767us/sample - loss: 0.3980 - accuracy: 0.8500 - val_loss: 0.4235 - val_accuracy: 0.8605\n",
      "Epoch 78/1000\n",
      "380/380 [==============================] - 0s 836us/sample - loss: 0.4044 - accuracy: 0.8526 - val_loss: 0.4427 - val_accuracy: 0.8605\n",
      "Epoch 79/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.4016 - accuracy: 0.8500 - val_loss: 0.4441 - val_accuracy: 0.8372\n",
      "Epoch 80/1000\n",
      "380/380 [==============================] - 0s 770us/sample - loss: 0.3877 - accuracy: 0.8447 - val_loss: 0.4600 - val_accuracy: 0.8605\n",
      "Epoch 81/1000\n",
      "380/380 [==============================] - 0s 706us/sample - loss: 0.3860 - accuracy: 0.8579 - val_loss: 0.4611 - val_accuracy: 0.8605\n",
      "Epoch 82/1000\n",
      "380/380 [==============================] - 0s 720us/sample - loss: 0.3788 - accuracy: 0.8632 - val_loss: 0.4595 - val_accuracy: 0.8372\n",
      "Epoch 83/1000\n",
      "380/380 [==============================] - 0s 784us/sample - loss: 0.3931 - accuracy: 0.8553 - val_loss: 0.4122 - val_accuracy: 0.8605\n",
      "Epoch 84/1000\n",
      "380/380 [==============================] - 0s 659us/sample - loss: 0.3870 - accuracy: 0.8553 - val_loss: 0.4567 - val_accuracy: 0.8605\n",
      "Epoch 85/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3822 - accuracy: 0.8553 - val_loss: 0.4843 - val_accuracy: 0.8605\n",
      "Epoch 86/1000\n",
      "380/380 [==============================] - 0s 686us/sample - loss: 0.3851 - accuracy: 0.8526 - val_loss: 0.4472 - val_accuracy: 0.8140\n",
      "Epoch 87/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3936 - accuracy: 0.8526 - val_loss: 0.4413 - val_accuracy: 0.8605\n",
      "Epoch 88/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3797 - accuracy: 0.8632 - val_loss: 0.4606 - val_accuracy: 0.8140\n",
      "Epoch 89/1000\n",
      "380/380 [==============================] - 0s 698us/sample - loss: 0.3879 - accuracy: 0.8579 - val_loss: 0.4598 - val_accuracy: 0.8372\n",
      "Epoch 90/1000\n",
      "380/380 [==============================] - 0s 789us/sample - loss: 0.3749 - accuracy: 0.8579 - val_loss: 0.5428 - val_accuracy: 0.7907\n",
      "Epoch 91/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3867 - accuracy: 0.8553 - val_loss: 0.6901 - val_accuracy: 0.8372\n",
      "Epoch 92/1000\n",
      "380/380 [==============================] - 0s 633us/sample - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.5065 - val_accuracy: 0.7907\n",
      "Epoch 93/1000\n",
      "380/380 [==============================] - 0s 720us/sample - loss: 0.3849 - accuracy: 0.8658 - val_loss: 0.4569 - val_accuracy: 0.8372\n",
      "Epoch 94/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.3683 - accuracy: 0.8605 - val_loss: 0.7082 - val_accuracy: 0.7442\n",
      "Epoch 95/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3768 - accuracy: 0.8605 - val_loss: 0.4767 - val_accuracy: 0.8372\n",
      "Epoch 96/1000\n",
      "380/380 [==============================] - 0s 690us/sample - loss: 0.3755 - accuracy: 0.8658 - val_loss: 0.4929 - val_accuracy: 0.8140\n",
      "Epoch 97/1000\n",
      "380/380 [==============================] - 0s 767us/sample - loss: 0.3748 - accuracy: 0.8579 - val_loss: 0.4846 - val_accuracy: 0.8605\n",
      "Epoch 98/1000\n",
      "380/380 [==============================] - 0s 714us/sample - loss: 0.3904 - accuracy: 0.8632 - val_loss: 0.4859 - val_accuracy: 0.8140\n",
      "Epoch 99/1000\n",
      "380/380 [==============================] - 0s 731us/sample - loss: 0.3687 - accuracy: 0.8737 - val_loss: 0.5272 - val_accuracy: 0.7907\n",
      "Epoch 100/1000\n",
      "380/380 [==============================] - 0s 669us/sample - loss: 0.3717 - accuracy: 0.8711 - val_loss: 0.4847 - val_accuracy: 0.8140\n",
      "Epoch 101/1000\n",
      "380/380 [==============================] - 0s 700us/sample - loss: 0.3689 - accuracy: 0.8605 - val_loss: 0.4945 - val_accuracy: 0.8140\n",
      "Epoch 102/1000\n",
      "380/380 [==============================] - 0s 696us/sample - loss: 0.3643 - accuracy: 0.8684 - val_loss: 0.5151 - val_accuracy: 0.7907\n",
      "Epoch 103/1000\n",
      "380/380 [==============================] - 0s 797us/sample - loss: 0.3707 - accuracy: 0.8605 - val_loss: 0.4331 - val_accuracy: 0.8605\n",
      "Epoch 104/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3670 - accuracy: 0.8684 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 105/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3611 - accuracy: 0.8658 - val_loss: 0.5869 - val_accuracy: 0.7674\n",
      "Epoch 106/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.3464 - accuracy: 0.8632 - val_loss: 0.4924 - val_accuracy: 0.8372\n",
      "Epoch 107/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3531 - accuracy: 0.8711 - val_loss: 0.4664 - val_accuracy: 0.8605\n",
      "Epoch 108/1000\n",
      "380/380 [==============================] - 0s 679us/sample - loss: 0.3756 - accuracy: 0.8684 - val_loss: 0.4378 - val_accuracy: 0.8605\n",
      "Epoch 109/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3687 - accuracy: 0.8605 - val_loss: 0.5116 - val_accuracy: 0.7907\n",
      "Epoch 110/1000\n",
      "380/380 [==============================] - 0s 674us/sample - loss: 0.3538 - accuracy: 0.8632 - val_loss: 0.5947 - val_accuracy: 0.7674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.3663 - accuracy: 0.8658 - val_loss: 0.5442 - val_accuracy: 0.7907\n",
      "Epoch 112/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.3475 - accuracy: 0.8789 - val_loss: 0.6929 - val_accuracy: 0.7209\n",
      "Epoch 113/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.3557 - accuracy: 0.8684 - val_loss: 0.5297 - val_accuracy: 0.8140\n",
      "Epoch 114/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.3611 - accuracy: 0.8684 - val_loss: 0.5800 - val_accuracy: 0.7674\n",
      "Epoch 115/1000\n",
      "380/380 [==============================] - 0s 657us/sample - loss: 0.3501 - accuracy: 0.8737 - val_loss: 0.5129 - val_accuracy: 0.8372\n",
      "Epoch 116/1000\n",
      "380/380 [==============================] - 0s 739us/sample - loss: 0.3555 - accuracy: 0.8684 - val_loss: 0.4785 - val_accuracy: 0.8140\n",
      "Epoch 117/1000\n",
      "380/380 [==============================] - 0s 709us/sample - loss: 0.3390 - accuracy: 0.8763 - val_loss: 0.5691 - val_accuracy: 0.7907\n",
      "Epoch 118/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.3548 - accuracy: 0.8737 - val_loss: 0.6914 - val_accuracy: 0.7209\n",
      "Epoch 119/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.3531 - accuracy: 0.8737 - val_loss: 0.6568 - val_accuracy: 0.7674\n",
      "Epoch 120/1000\n",
      "380/380 [==============================] - 0s 752us/sample - loss: 0.3499 - accuracy: 0.8737 - val_loss: 0.5934 - val_accuracy: 0.7907\n",
      "Epoch 121/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.3507 - accuracy: 0.8737 - val_loss: 0.5797 - val_accuracy: 0.7209\n",
      "Epoch 122/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.3253 - accuracy: 0.8789 - val_loss: 0.9779 - val_accuracy: 0.7442\n",
      "Epoch 123/1000\n",
      "380/380 [==============================] - 0s 671us/sample - loss: 0.3531 - accuracy: 0.8763 - val_loss: 0.8928 - val_accuracy: 0.7674\n",
      "Epoch 124/1000\n",
      "380/380 [==============================] - 0s 666us/sample - loss: 0.3485 - accuracy: 0.8711 - val_loss: 0.5126 - val_accuracy: 0.7674\n",
      "Epoch 125/1000\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.87 - 0s 643us/sample - loss: 0.3410 - accuracy: 0.8763 - val_loss: 0.5635 - val_accuracy: 0.7674\n",
      "Epoch 126/1000\n",
      "380/380 [==============================] - 0s 693us/sample - loss: 0.3407 - accuracy: 0.8737 - val_loss: 0.7511 - val_accuracy: 0.7209\n",
      "Epoch 127/1000\n",
      "380/380 [==============================] - 0s 687us/sample - loss: 0.3484 - accuracy: 0.8737 - val_loss: 0.4575 - val_accuracy: 0.7907\n",
      "Epoch 128/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.3330 - accuracy: 0.8763 - val_loss: 0.7705 - val_accuracy: 0.7674\n",
      "Epoch 129/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.3318 - accuracy: 0.8921 - val_loss: 0.6232 - val_accuracy: 0.7209\n",
      "Epoch 130/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.3139 - accuracy: 0.8868 - val_loss: 0.8229 - val_accuracy: 0.7674\n",
      "Epoch 131/1000\n",
      "380/380 [==============================] - 0s 685us/sample - loss: 0.3363 - accuracy: 0.8789 - val_loss: 0.5543 - val_accuracy: 0.7907\n",
      "Epoch 132/1000\n",
      "380/380 [==============================] - 0s 684us/sample - loss: 0.3354 - accuracy: 0.8789 - val_loss: 0.6605 - val_accuracy: 0.7209\n",
      "Epoch 133/1000\n",
      "380/380 [==============================] - 0s 657us/sample - loss: 0.3545 - accuracy: 0.8737 - val_loss: 0.5566 - val_accuracy: 0.8140\n",
      "Epoch 134/1000\n",
      "380/380 [==============================] - 0s 725us/sample - loss: 0.3362 - accuracy: 0.8789 - val_loss: 0.9051 - val_accuracy: 0.7442\n",
      "Epoch 135/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3255 - accuracy: 0.8763 - val_loss: 0.5515 - val_accuracy: 0.7907\n",
      "Epoch 136/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.3402 - accuracy: 0.8921 - val_loss: 0.8660 - val_accuracy: 0.7442\n",
      "Epoch 137/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.3768 - accuracy: 0.8632 - val_loss: 0.5892 - val_accuracy: 0.7674\n",
      "Epoch 138/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.3203 - accuracy: 0.8816 - val_loss: 0.6429 - val_accuracy: 0.7674\n",
      "Epoch 139/1000\n",
      "380/380 [==============================] - 0s 673us/sample - loss: 0.3330 - accuracy: 0.8816 - val_loss: 0.7452 - val_accuracy: 0.7442\n",
      "Epoch 140/1000\n",
      "380/380 [==============================] - 0s 702us/sample - loss: 0.3755 - accuracy: 0.8658 - val_loss: 0.4134 - val_accuracy: 0.8605\n",
      "Epoch 141/1000\n",
      "380/380 [==============================] - 0s 696us/sample - loss: 0.3306 - accuracy: 0.8737 - val_loss: 0.5221 - val_accuracy: 0.7907\n",
      "Epoch 142/1000\n",
      "380/380 [==============================] - 0s 691us/sample - loss: 0.3354 - accuracy: 0.8763 - val_loss: 0.6263 - val_accuracy: 0.7674\n",
      "Epoch 143/1000\n",
      "380/380 [==============================] - 0s 672us/sample - loss: 0.3304 - accuracy: 0.8816 - val_loss: 0.4640 - val_accuracy: 0.8140\n",
      "Epoch 144/1000\n",
      "380/380 [==============================] - 0s 709us/sample - loss: 0.3157 - accuracy: 0.8842 - val_loss: 0.5844 - val_accuracy: 0.7674\n",
      "Epoch 145/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.3334 - accuracy: 0.8816 - val_loss: 0.7654 - val_accuracy: 0.7674\n",
      "Epoch 146/1000\n",
      "380/380 [==============================] - 0s 652us/sample - loss: 0.3250 - accuracy: 0.8816 - val_loss: 0.5843 - val_accuracy: 0.7907\n",
      "Epoch 147/1000\n",
      "380/380 [==============================] - 0s 708us/sample - loss: 0.3255 - accuracy: 0.8789 - val_loss: 0.5898 - val_accuracy: 0.7907\n",
      "Epoch 148/1000\n",
      "380/380 [==============================] - 0s 696us/sample - loss: 0.3383 - accuracy: 0.8711 - val_loss: 0.5152 - val_accuracy: 0.7907\n",
      "Epoch 149/1000\n",
      "380/380 [==============================] - 0s 678us/sample - loss: 0.3244 - accuracy: 0.8763 - val_loss: 0.5274 - val_accuracy: 0.8140\n",
      "Epoch 150/1000\n",
      "380/380 [==============================] - 0s 676us/sample - loss: 0.3367 - accuracy: 0.8868 - val_loss: 0.5967 - val_accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "# 과적합을 줄이기 위해 네트워크를 단순화\n",
    "model = Sequential()\n",
    "# model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "model.add(Dense(80, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 최소 오차 20번 나오면 자동 종료\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "# 학습\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                 epochs=1000, \n",
    "                 batch_size=2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수화\n",
    "def overfit1():\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "    model.add(Dense(80, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 최소 오차 20번 나오면 자동 종료\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[early_stopping])\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patience를 감소시킴\n",
    "def overfit2():\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "    model.add(Dense(80, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 최소 오차 20번 나오면 자동 종료\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[early_stopping])\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 80)                1440      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 9,215\n",
      "Trainable params: 9,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 380 samples, validate on 43 samples\n",
      "Epoch 1/1000\n",
      "380/380 [==============================] - 1s 2ms/sample - loss: 0.8150 - accuracy: 0.7921 - val_loss: 0.5828 - val_accuracy: 0.8605\n",
      "Epoch 2/1000\n",
      "380/380 [==============================] - 0s 749us/sample - loss: 0.5286 - accuracy: 0.8395 - val_loss: 0.5145 - val_accuracy: 0.8605\n",
      "Epoch 3/1000\n",
      "380/380 [==============================] - 0s 670us/sample - loss: 0.4648 - accuracy: 0.8500 - val_loss: 0.5539 - val_accuracy: 0.8605\n",
      "Epoch 4/1000\n",
      "380/380 [==============================] - 0s 682us/sample - loss: 0.4538 - accuracy: 0.8500 - val_loss: 0.4399 - val_accuracy: 0.8605\n",
      "Epoch 5/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4303 - accuracy: 0.8500 - val_loss: 0.4263 - val_accuracy: 0.8605\n",
      "Epoch 6/1000\n",
      "380/380 [==============================] - 0s 653us/sample - loss: 0.4394 - accuracy: 0.8500 - val_loss: 0.4905 - val_accuracy: 0.8605\n",
      "Epoch 7/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4358 - accuracy: 0.8500 - val_loss: 0.4328 - val_accuracy: 0.8605\n",
      "Epoch 8/1000\n",
      "380/380 [==============================] - 0s 663us/sample - loss: 0.4270 - accuracy: 0.8500 - val_loss: 0.4397 - val_accuracy: 0.8605\n",
      "Epoch 9/1000\n",
      "380/380 [==============================] - 0s 689us/sample - loss: 0.4301 - accuracy: 0.8500 - val_loss: 0.4369 - val_accuracy: 0.8605\n",
      "Epoch 10/1000\n",
      "380/380 [==============================] - 0s 681us/sample - loss: 0.4341 - accuracy: 0.8447 - val_loss: 0.5552 - val_accuracy: 0.8605\n",
      "Epoch 11/1000\n",
      "380/380 [==============================] - 0s 695us/sample - loss: 0.4392 - accuracy: 0.8500 - val_loss: 0.4325 - val_accuracy: 0.8605\n",
      "Epoch 12/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4268 - accuracy: 0.8500 - val_loss: 0.4314 - val_accuracy: 0.8605\n",
      "Epoch 13/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4295 - accuracy: 0.8500 - val_loss: 0.4421 - val_accuracy: 0.8605\n",
      "Epoch 14/1000\n",
      "380/380 [==============================] - 0s 697us/sample - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.4310 - val_accuracy: 0.8605\n",
      "Epoch 15/1000\n",
      "380/380 [==============================] - 0s 683us/sample - loss: 0.4248 - accuracy: 0.8500 - val_loss: 0.4467 - val_accuracy: 0.8605\n",
      "Epoch 16/1000\n",
      "380/380 [==============================] - 0s 677us/sample - loss: 0.4229 - accuracy: 0.8500 - val_loss: 0.4312 - val_accuracy: 0.8605\n",
      "Epoch 17/1000\n",
      "380/380 [==============================] - 0s 699us/sample - loss: 0.4238 - accuracy: 0.8500 - val_loss: 0.4374 - val_accuracy: 0.8605\n",
      "Epoch 18/1000\n",
      "380/380 [==============================] - 0s 688us/sample - loss: 0.4265 - accuracy: 0.8500 - val_loss: 0.4318 - val_accuracy: 0.8605\n",
      "Epoch 19/1000\n",
      "380/380 [==============================] - 0s 692us/sample - loss: 0.4236 - accuracy: 0.8500 - val_loss: 0.4326 - val_accuracy: 0.8605\n",
      "Epoch 20/1000\n",
      "380/380 [==============================] - 0s 675us/sample - loss: 0.4298 - accuracy: 0.8500 - val_loss: 0.4358 - val_accuracy: 0.8605\n",
      "Epoch 21/1000\n",
      "380/380 [==============================] - 0s 694us/sample - loss: 0.4244 - accuracy: 0.8500 - val_loss: 0.4345 - val_accuracy: 0.8605\n"
     ]
    }
   ],
   "source": [
    "model, hist = overfit2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 80)                1440      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 9,215\n",
      "Trainable params: 9,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 0.9740]) # 값을 반영하여 변경\n",
    "\n",
    "# 오른쪽 y 축 설정\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 0.43425939311372475 /정확도: 85.10638475418091 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Overfit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0]\n",
      " [ 7  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 - 혼동 행렬\n",
    "print(x_test.shape)\n",
    "y_test_pred = model.predict_classes(x_test)\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "ax = sb.heatmap(c_matrix, annot=True, \n",
    "                 xticklabels=['사망', '생존'], \n",
    "                 yticklabels=['사망', '생존'], cbar=False, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "print(c_matrix)\n",
    "\n",
    "# [[490   0]\n",
    "#  [ 12 148]]\n",
    "# [[사망자 맞춘 갯수   사망자 틀린 갯수]\n",
    "#  [생존자 틀린 갯수   생존자 맞춘갯수]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 - ROC 곡선\n",
    "y_test_pred_probs = model.predict(x_test)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_test_pred_probs)\n",
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0,1],[0,1],'--', color='black') #diagonal line\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
